@article{jazi2021an,
abstract = {In emotion-aware music recommender systems, the user's current emotion is identified and considered in recommending music to him. We have two motivations to extend the existing systems: (1) to the best of our knowledge, the current systems first estimate the user's emotions and then suggest music based on it. Therefore, the emotion estimation error affects the recommendation accuracy. (2) Studies show that the pattern of users' interactions with input devices can reflect their emotions. However, these patterns have not been used yet in emotion-aware music recommender systems. In this study, a music recommender system is proposed to suggest music based on users' keystrokes and mouse clicks patterns. Unlike the previous ones, the proposed system maps these patterns directly to the user's favorite music, without labeling its current emotion. The results show that even though this system does not use any additional device, it is highly accurate compared to previous methods.},
author = {{Yousefian Jazi}, Saba and Kaedi, Marjan and Fatemi, Afsaneh},
doi = {10.1007/s11042-020-10386-7},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Collaborative filtering,Emotion-aware music recommender,Keystroke pattern,Mouse click pattern},
number = {9},
pages = {13559--13574},
publisher = {Springer Science and Business Media {LLC}},
title = {{An emotion-aware music recommender system: bridging the user's interaction and music recommendation}},
volume = {80},
year = {2021}
}
@article{sassi2020how,
abstract = {To simplify effective music filtering, recommender systems (RS) have received great attention from both industry and academia area. To select which music to recommend, traditional RS uses an approximation of users' real interests. However, while discarding users' contexts, profiles information is not able to reflect their exact needs and to provide overpowering recommendations. One of the main issues that have to be considered before the conception of context-aware recommender systems (CARS) is the estimation of the relevance of contextual information. The use of irrelevant or superfluous contextual factors can generate serious problems about the complexity and the quality of recommendations. In this paper, we introduce a multi-dimensional context model for music CARS. We started by the acquisition of explicit items rating from a population in various possible contextual situations. Thus, we proposed a user-based methodology aiming to judge the relation between contextual factors and musical genres. Next, we applied the Multiple Linear Regression technique on users' perceived ratings, to define an order of importance between contextual dimensions. We described raw collected data with basic statistics about the created dataset. We also summarized the key results and discussed key findings. Finally, we propose a new framework for Music CARS.},
author = {{Ben Sassi}, Imen and {Ben Yahia}, Sadok},
doi = {10.1007/s00530-020-00717-x},
issn = {14321882},
journal = {Multimedia Systems},
keywords = {Context model,Multiple Linear Regression,Music recommendation,Recommender systems,User-based study},
month = {nov},
number = {2},
pages = {143--160},
publisher = {Springer Science and Business Media {LLC}},
title = {{How does context influence music preferences: a user-based study of the effects of contextual information on users' preferred music}},
volume = {27},
year = {2021}
}
@article{y�rekli2021exploring,
abstract = {In music recommender systems, automatic playlist continuation is an emerging task that aims to improve users' listening experience by recommending music in line with their musical taste. The typical approach towards this goal is to identify playlist characteristics by inspecting the existing tracks (i.e., seeds) in target playlists. However, seeds are not always available, especially when users create new playlists. For such cold-start situations, user-generated titles can be a good starting point to understand the intended purpose of users. This paper investigates the effectiveness of titles as an auxiliary data source for playlists suffering from the cold-start problem. Employing three naive recommendation models, we conduct experiments on one million music playlists from the Spotify platform. Our analyses show that the prevalent attitude in naming playlists results in highly accurate recommendations for playlists concerning a specific theme, such as albums, artists, and soundtracks. As the title space moves away from a particular theme, recommendation accuracy drops. Furthermore, the correlation between the common preference of a title and its usability in recommendation is quite weak; a title without a common sense may be useless in recommender systems, even though many users favor that title. Consequently, our findings serve as a guideline to develop title-aware recommendation approaches that can provide coherent continuations to the cold-start playlists.},
author = {Y{\"{u}}rekli, Ali and Bilge, Alper and Kaleli, Cihan},
doi = {10.1007/s12652-020-02777-3},
issn = {18685145},
journal = {Journal of Ambient Intelligence and Humanized Computing},
keywords = {Automatic playlist continuation,Cold-start problem,Music recommender systems,Playlist titles,User-generated content},
publisher = {Springer Science and Business Media {LLC}},
title = {{Exploring playlist titles for cold-start music recommendation: an effectiveness analysis}},
year = {2021}
}
@article{wundervald2021clusterbased,
abstract = {Increasingly, music recommendations are influencing user listening behavior, which naturally impacts the music industry, as well as the cultural and social aspects of our society. This has opened up a research area, namely the identification of biases introduced by recommender systems in the music context. Recent research, which focused on users of the Last.fm platform found that state-of-the-art music recommendation systems frequently tend to favor already popular items. To this end, we propose a new method for predicting music recommendations, which relies on a cluster-based quotas system. By assuming the distribution of the popularity of artists to have a latent variable that is estimated with a Gaussian Mixture, we find the underlying popularity clusters and use them to make the predictions by quotas that relate to each cluster mixing proportion, in a way that the resulting popularity distribution in the recommendations is closer to the popularity distribution seen in the data. In our experiments with the Last.fm data, our final predictions increased the recommendation frequencies of less popular artists, while preserving the specific characteristics of each algorithm. The GAP(g)r and mean average error (MAE) metrics are improved, showing that our recommendations are more accurate and approximate to the expected popularity of the artists in each user profile.},
author = {Wundervald, Bruna},
doi = {10.1007/s13735-020-00203-0},
issn = {2192662X},
journal = {International Journal of Multimedia Information Retrieval},
keywords = {Cluster-based,Fairness,Music recommendation systems,Popularity bias,Prediction quotas},
number = {1},
pages = {25--32},
publisher = {Springer Science and Business Media {LLC}},
title = {{Cluster-based quotas for fairness improvements in music recommendation systems}},
volume = {10},
year = {2021}
}
@article{wang2021came,
abstract = {Traditional recommendation methods suffer from limited performance, which can be addressed by incorporating abundant auxiliary/side information. This article focuses on a personalized music recommender system that incorporates rich content and context data in a unified and adaptive way to address the abovementioned problems. The content information includes music textual content, such as metadata, tags, and lyrics, and the context data incorporate users' behaviors, including music listening records, music playing sequences, and sessions. Specifically, a heterogeneous information network (HIN) is first presented to incorporate different kinds of content and context data. Then, a novel method called content- and context-aware music embedding (CAME) is proposed to obtain the low-dimension dense real-valued feature representations (embeddings) of music pieces from HIN. Especially, one music piece generally highlights different aspects when interacting with various neighbors, and it should have different representations separately. CAME seamlessly combines deep learning techniques, including convolutional neural networks and attention mechanisms, with the embedding model to capture the intrinsic features of music pieces as well as their dynamic relevance and interactions adaptively. Finally, we further infer users' general musical preferences as well as their contextual preferences for music and propose a content- and context-aware music recommendation method. Comprehensive experiments as well as quantitative and qualitative evaluations have been performed on real-world music data sets, and the results show that the proposed recommendation approach outperforms state-of-the-art baselines and is able to handle sparse data effectively.},
author = {Wang, Dongjing and Zhang, Xin and Yu, Dongjin and Xu, Guandong and Deng, Shuiguang},
doi = {10.1109/TNNLS.2020.2984665},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Attention,content,context-aware,embedding,recommender systems},
month = {mar},
number = {3},
pages = {1375--1388},
pmid = {32305946},
publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
title = {{CAME: Content- And Context-Aware Music Embedding for Recommendation}},
volume = {32},
year = {2021}
}
@article{zangerle2021leveraging,
abstract = {Mood and emotion play an important role when it comes to choosing musical tracks to listen to. In the field of music information retrieval and recommendation, emotion is considered contextual information that is hard to capture, albeit highly influential. In this study, we analyze the connection between users' emotional states and their musical choices. Particularly, we perform a large-scale study based on two data sets containing 560,000 and 90,000 #nowplaying tweets, respectively. We extract affective contextual information from hashtags contained in these tweets by applying an unsupervised sentiment dictionary approach. Subsequently, we utilize a state-of-The-Art network embedding method to learn latent feature representations of users, tracks and hashtags. Based on both the affective information and the latent features, a set of eight ranking methods is proposed. We find that relying on a ranking approach that incorporates the latent representations of users and tracks allows for capturing a user's general musical preferences well (regardless of used hashtags or affective information). However, for capturing context-specific preferences (a more complex and personal ranking task), we find that ranking strategies that rely on affective information and that leverage hashtags as context information outperform the other ranking strategies.},
author = {Zangerle, Eva and Chen, Chih Ming and Tsai, Ming Feng and Yang, Yi Hsuan},
doi = {10.1109/TAFFC.2018.2846596},
issn = {19493045},
journal = {IEEE Transactions on Affective Computing},
keywords = {Emotion in music,emotion regulation,hashtags,microblogging,music recommendation,ranking,sentiment detection},
number = {1},
pages = {78--91},
publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
title = {{Leveraging Affective Hashtags for Ranking Music Recommendations}},
volume = {12},
year = {2021}
}
@article{polignano2021towards,
abstract = {Decision making is the cognitive process of identifying and choosing alternatives based on preferences, beliefs, and degree of importance given by the decision maker to objects or actions. For instance, choosing which movie to watch is a simple, small-sized decision-making process. Recommender systems help people to make this kind of choices, usually by computing a short list of suggestions that reduces the space of possible options. These systems are strongly based on the knowledge of user preferences but, in order to fully support people, they should be grounded on a holistic view of the user behavior, that includes also how emotions, mood, and personality traits influence her choosing patterns. In this work, we investigate how to include emotional aspects in the recommendation process. We suggest that the affective state of the user, defined by a set of emotions (e.g., joy, surprise), constitutes part of choosing situation that should be taken into account when modeling user preferences. The main contribution of the paper is a general emotion-aware computational model based on affective user profiles in which each preference, such as a 5-star rating on a movie, is associated with the affective state felt by the user at the time when that preference was collected. The model estimates whether an unseen item is suitable for the current affective state of the user, by computing an affective coherence score that takes into account both the affective user profile and not-affective item features. The approach has been implemented into an Emotion-aware Music Recommender System, whose effectiveness has been assessed by performing in-vitro experiments on two benchmark datasets. The main outcome is that our system showed improved accuracy of recommendations compared to baselines which include no affective information in the recommendation model.},
author = {Polignano, Marco and Narducci, Fedelucio and de Gemmis, Marco and Semeraro, Giovanni},
doi = {10.1016/j.eswa.2020.114382},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Affective Computing,Decision Making,Emotions,Music Recommendation,Recommender Systems,myPersonality},
month = {may},
pages = {114382},
publisher = {Elsevier {BV}},
title = {{Towards Emotion-aware Recommender Systems: an Affective Coherence Model based on Emotion-driven Behaviors}},
volume = {170},
year = {2021}
}
@article{kim2020pepmusic,
abstract = {Music can motivate many daily activities as it can regulate mood, increase productivity and sports performance, and raise spirits. However, we know little about how to recommend songs that are motivational for people given their contexts and activities. As a first step towards dealing with this issue, we adopt a theory-driven approach and operationalize the Brunel Music Rating Inventory (BMRI) to identify motivational qualities of music from the audio signal. When we look at frequently listened songs for 14 common daily activities through the lens of motivational music qualities, we find that they are clustered into three high-level latent activity groups: calm, vibrant, and intense. We show that our BMRI features can accurately classify songs in the three classes, thus enabling tools to select and recommend activity-specific songs from existing music libraries without any input required from user. We present the results of a preliminary user evaluation of our song recommender (called PepMusic) and discuss the implications for recommending songs for daily activities.},
author = {Kim, Yongsung and Aiello, Luca Maria and Quercia, Daniele},
doi = {10.1140/epjds/s13688-020-0221-9},
issn = {21931127},
journal = {EPJ Data Science},
keywords = {Daily activities,Motivational qualities,Music,Music recommendation},
month = {may},
number = {1},
publisher = {Springer Science and Business Media {LLC}},
title = {{PepMusic: motivational qualities of songs for daily activities}},
volume = {9},
year = {2020}
}
@article{wang2020heterogeneous,
abstract = {In the process of the rapid development of mobile networks, music recommendation systems (MRSs) have experienced considerable success in recent years. Conventional music recommendation systems are, however, in general based on the simple user–track relationships or the content of songs and recommend songs according to intrinsic factors. Furthermore they do not consider the users' contextual factors towards providing them with a more interpretable, efficient and smart recommendation experience. To address these issues, we propose a novel Heterogeneous Information Network-based Music Recommendation System (HIN-MRS). By considering the extrinsic factors, such as contextual factors, internal factors, such as the user's personalized preference, and the heterogeneous relationship between items of song information, this method can perceive the user's music selection from multiple aspects, automatically maintain the user's playlist and improve the user's music experience. First we used the obtained textual data to extract the user's music preference to provide the topic which is usually related to the contextual factors, by means of which an HIN-MRS can realize the perception of the mobile environment. Second, after determining the topics, we built a small-scale HIN of songs (song HIN) according to topics and used a graph-based algorithm to generate recommendations. The recommendation method based on an HIN renders the recommendation process more efficient and the recommendation results more accurate and increases the users satisfaction. The results of our final experiments also prove the significant advantages of the proposed model over the conventional approaches.},
author = {Wang, Ranran and Ma, Xiao and Jiang, Chi and Ye, Yi and Zhang, Yin},
doi = {10.1016/j.comcom.2019.12.002},
issn = {1873703X},
journal = {Computer Communications},
keywords = {Heterogeneous information networks,Mobile networks,Music recommendation},
pages = {429--437},
publisher = {Elsevier {BV}},
title = {{Heterogeneous information network-based music recommendation system in mobile networks}},
volume = {150},
year = {2020}
}
@article{wilhelm2020using,
abstract = {Older adults commonly experience hearing loss that negatively affects the quality of life and creates barriers to effective therapeutic interactions as well as music listening. Music therapists have the potential to address some needs of older adults, but the effectiveness of music interventions is dependent on the perception of spoken and musical stimuli. Nonauditory information, such as contextual (e.g., keywords, picture related to song) and visual cues (e.g., clear view of singer's face), can improve speech perception. The purpose of this study was to examine the benefit of contextual and visual cues on sung word recognition in the presence of guitar accompaniment. The researcher tested 24 community-dwelling older adult hearing aid (HA) users recruited through a university HA clinic and laboratory under 3 study conditions: (a) auditory stimuli only, (b) auditory stimuli with contextual cues, and (c) auditory stimuli with visual cues. Both visual and contextual nonauditory cues benefited participants on sung word recognition. Participants' music background and training were predictive of success without nonauditory cues, and visual cues provided greater benefit than contextual cues. Based on the results of this study, it is recommended that music therapists increase the accessibility of music interventions reliant upon lyric recognition through the incorporation of clear visual and contextual cues.},
author = {Wilhelm, Lindsey A.},
doi = {10.1093/jmt/thaa009},
issn = {20537395},
journal = {Journal of Music Therapy},
keywords = {Hearing loss,Lyrics,Music therapy,Nonauditory cues,Older adults},
month = {jun},
number = {4},
pages = {379--405},
pmid = {32574363},
publisher = {Oxford University Press ({OUP})},
title = {{Using contextual and visual cues to improve sung word recognition in hearing aid users}},
volume = {57},
year = {2020}
}
@article{pereznunez2019improving,
abstract = {The aim of Recommender Systems is to suggest items (products) to satisfy each user's particular taste. Representation strategies play a very important role in these systems, as an adequate codification of users and items is expected to ease the induction of a model which synthesizes their tastes and make better recommendations. However, in addition to gathering information about users' tastes, there is an additional aspect that can be relevant for a proper codification strategy, namely the order in which the user interacted with the items. In this paper, several encoding strategies based on neural networks are analyzed and applied to solve two different recommendation tasks in the context of music playlists. The results show that the order in which the musical pieces were listened to is relevant for the codification of items (songs). We also find that the encoding of user profiles should use a different amount of historical data depending on the learning task to be solved. In other words, we do not always have to use all the available data; sometimes, it is better to discard old information, as tastes change over time.},
author = {P{\'{e}}rez-N{\'{u}}{\~{n}}ez, Pablo and Luaces, Oscar and Bahamonde, Antonio and D{\'{i}}ez, Jorge},
doi = {10.1007/s13748-019-00199-7},
issn = {21926360},
journal = {Progress in Artificial Intelligence},
keywords = {Collaborative filtering,Matrix factorization,Profiles,Recommender systems},
month = {jul},
number = {1},
pages = {67--75},
publisher = {Springer Science and Business Media {LLC}},
title = {{Improving recommender systems by encoding items and user profiles considering the order in their consumption history}},
volume = {9},
year = {2020}
}
@article{pichl2020user,
abstract = {In the last decade, music consumption has changed dramatically as humans have increasingly started to use music streaming platforms. While such platforms provide access to millions of songs, the sheer volume of choices available renders it hard for users to find songs they like. Consequently, the task of finding music the user likes is often mitigated by music recommender systems, which aim to provide recommendations that match the user's current context. Particularly in the field of music recommendation, adapting recommendations to the user's current context is critical as, throughout the day, users listen to different music in numerous different contexts and situations. Therefore, we propose a multi-context-aware user model and track recommender system that jointly exploit information about the current situation and musical preferences of users. Our proposed system clusters users based on their situational context features and similarly, clusters music tracks based on their content features. By conducting a series of offline experiments, we show that by relying on Factorization Machines for the computation of recommendations, the proposed multi-context-aware user model successfully leverages interaction effects between user listening histories, situational, and track content information, substantially outperforming a set of baseline recommender systems.},
author = {Pichl, Martin and Zangerle, Eva},
doi = {10.1007/s11042-020-09890-7},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Context-aware recommender systems,Personalization,Recommender systems,User modeling},
month = {oct},
publisher = {Springer Science and Business Media {LLC}},
title = {{User models for multi-context-aware music recommendation}},
year = {2020}
}
@article{roy2020imusic,
abstract = {Music has emerged to be of paramount importance to humanity and is not only considered as a source of entertainment but also an agent that causes social and psychological influences. A large number of existing digital music libraries have improved awareness among people through the music recommendation approach. However, several critical technical challenges still require attention and must be well–addressed to provide a reliable recommendation to music listeners. In Indian Classical Music, Raga is composed of coalescing diverse musical note structures. The history of classical music unveils that every raga possesses some distinct sessions. With a vast collection of classical music files in online music libraries, locating and listening to classical music is no more a difficult task. However, searching and listening to the audio of one's preference may not be simple as it must instinctively satisfy the listener's preference in a precise session. In this paper, a system termed as iMusic has been proposed to classify, analyze, and recommend the session–sensitive performance of Indian classical music by analyzing the musical note structures followed by features matching. Available note-patterns in the raga performance have been illustrated using a deep neural network and a set of machine learning algorithms where raga samples have been represented as inputs in the projected network and are classified based on the performing sessions. A context-aware k-means clustering algorithm has also been illustrated, entitled as a data filtering algorithm. The proficiency of the filtering algorithm has been established in two ways. Primarily, as a data-sensitive analysis, and second as empirical studies on synthetically obtained real classical music dataset (https://github.com/SamarjitRoy89/iMusic.git) to put on the hybrid music recommendation. In this work, a case-study of session-sensitive Indian music recommender system has been demonstrated using key-strategies viz. listener modelling, representation learning, and music profiling. Eventually, several evaluation metrics have been discussed to characterize the effectiveness of proposed representation learning-based playing session-sensitive music recommendation strategies. The proposed iMusic system renders data classification accuracy of $\sim$ 88%. Such a framework could provide a useful basis regarding studies on hybrid music recommendation systems based on the usefulness of end-users.},
author = {Roy, Samarjit and Biswas, Mousumi and De, Debashis},
doi = {10.1007/s11042-020-09126-8},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Classical music,Clustering,Computational musicology,Deep neural network,Hybrid collaborative filtering,Internet of music things,Music recommendation,Representation learning},
month = {jun},
number = {33-34},
pages = {24119--24155},
publisher = {Springer Science and Business Media {LLC}},
title = {{iMusic: a session-sensitive clustered classical music recommender system using contextual representation learning}},
volume = {79},
year = {2020}
}
@article{mcferran2019adolescents,
abstract = {Music therapists have been working with, writing about, and researching their work with adolescents for many decades. This paper provides a reflective review of the research literature in the field that is categorized in three contexts: education, mental health, and community. Grouping knowledge in this way affords a new perspective on how music therapists describe adolescents, including the terms we use to describe them, the types of programs we offer, the approaches to research that are most popular, and the way we talk about the focus of therapy. Distinctions between research in these fields are highlighted, with reference to the beliefs and values that are most congruent with each of these contexts. Following this reflective review on the literature, I provide five recommendations for consideration by researchers and practitioners. These include: determining if and when evidence is an appropriate focus; continuing to seek understanding; not underestimating the value of positive experiences; avoiding an exclusive focus on the music therapist's perspective; and being realistic about the outcomes of group versus individual therapy. The paper concludes with an illustrative example to emphasize how one adolescent might be "seen" differently in each context.},
author = {McFerran, Katrina Skewes},
doi = {10.1093/mtp/miz014},
issn = {20537387},
journal = {Music Therapy Perspectives},
keywords = {adolescents,critical,literature review,music,music therapy,young people,youth},
month = {nov},
number = {1},
pages = {80--88},
publisher = {Oxford University Press ({OUP})},
title = {{Adolescents and Music Therapy: Contextualized Recommendations for Research and Practice}},
volume = {38},
year = {2020}
}
@article{sanchezmoreno2020timeaware,
abstract = {Online streaming services have become the most popular way of listening to music. The majority of these services are endowed with recommendation mechanisms that help users to discover songs and artists that may interest them from the vast amount of music available. However, many are not reliable as they may not take into account contextual aspects or the ever-evolving user behavior. Therefore, it is necessary to develop systems that consider these aspects. In the field of music, time is one of the most important factors influencing user preferences and managing its effects, and is the motivation behind the work presented in this paper. Here, the temporal information regarding when songs are played is examined. The purpose is to model both the evolution of user preferences in the form of evolving implicit ratings and user listening behavior. In the collaborative filtering method proposed in this work, daily listening habits are captured in order to characterize users and provide them with more reliable recommendations. The results of the validation prove that this approach outperforms other methods in generating both context-aware and context-free recommendations.},
author = {S{\'{a}}nchez-Moreno, Diego and Zheng, Yong and Moreno-Garc{\'{i}}a, Mar{\'{i}}a N.},
doi = {10.3390/APP10155324},
issn = {20763417},
journal = {Applied Sciences (Switzerland)},
keywords = {CARS,Collaborative filtering,Implicit ratings,TARS,Time-aware music recommender systems},
month = {jul},
number = {15},
pages = {5324},
publisher = {{MDPI} {AG}},
title = {{Time-aware music recommender systems: Modeling the evolution of implicit user preferences and user listening habits in a collaborative filtering approach}},
volume = {10},
year = {2020}
}
@article{ning2020personalized,
abstract = {Collaborative filtering technology is currently the most successful and widely used technology in the recommendation system. It has achieved rapid development in theoretical research and practice. It selects information and similarity relationships based on the user's history and collects others that are the same as the user's hobbies. User's evaluation information is to generate recommendations. The main research is the inadequate combination of context information and the mining of new points of interest in the context-aware recommendation process. On the basis of traditional recommendation technology, in view of the characteristics of the context information in music recommendation, a personalized and personalized music based on popularity prediction is proposed. Recommended algorithm is MRAPP (Media Recommendation Algorithm based on Popularity Prediction). The algorithm first analyzes the user's contextual information under music recommendation and classifies and models the contextual information. The traditional content-based recommendation technology CB calculates the recommendation results and then, for the problem that content-based recommendation technology cannot recommend new points of interest for users, introduces the concept of popularity. First, we use the memory and forget function to reduce the score and then consider user attributes and product attributes to calculate similarity; secondly, we use logistic regression to train feature weights; finally, appropriate weights are used to combine user-based and item-based collaborative filtering recommendation results. Based on the above improvements, the improved collaborative filtering recommendation algorithm in this paper has greatly improved the prediction accuracy. Through theoretical proof and simulation experiments, the effectiveness of the MRAPP algorithm is demonstrated.},
author = {Ning, Hui and Li, Qian},
doi = {10.1155/2020/6643888},
editor = {Wang, Wei},
issn = {10990526},
journal = {Complexity},
pages = {1--11},
publisher = {Hindawi Limited},
title = {{Personalized music recommendation simulation based on improved collaborative filtering algorithm}},
volume = {2020},
year = {2020}
}
@article{sanchezmoreno2020exploiting,
abstract = {Recent research in the field of recommender systems focuses on the incorporation of social information into collaborative filtering methods to improve the reliability of recommendations. Social networks enclose valuable data regarding user behavior and connections that can be exploited in this area to infer knowledge about user preferences and social influence. The fact that streaming music platforms have some social functionalities also allows this type of information to be used for music recommendation. In this work, we take advantage of the friendship structure to address a type of recommendation bias derived from the way collaborative filtering methods compute the neighborhood. These methods restrict the rating predictions for a user to the items that have been rated by their nearest neighbors while leaving out other items that might be of his/her interest. This problem is different from the popularity bias caused by the power-law distribution of the item rating frequency (long-tail), well-known in the music domain, although both shortcomings can be related. Our proposal is based on extending and diversifying the neighborhood by capturing trust and homophily effects between users through social structure metrics. The results show an increase in potentially recommendable items while reducing recommendation error rates.},
author = {S{\'{a}}nchez-Moreno, Diego and Batista, Vivian L{\'{o}}pez and Vicente, M. Dolores Mu{\~{n}}oz and L{\'{a}}zaro, {\'{A}}ngel Luis S{\'{a}}nchez and Moreno-Garc{\'{i}}a, Mar{\'{i}}a N.},
doi = {10.3390/INFO11090439},
issn = {20782489},
journal = {Information (Switzerland)},
keywords = {Collaborative filtering,Homophily,Music recommender systems,Social influence,Social trust,Streaming services},
month = {sep},
number = {9},
pages = {439},
publisher = {{MDPI} {AG}},
title = {{Exploiting the user social context to address neighborhood bias in collaborative filtering music recommender systems}},
volume = {11},
year = {2020}
}
@article{draves2019teaching,
abstract = {The purpose of this particularistic case study was to explore Paul's teacher identity in his first year as a music educator. I chose Paul purposively because, while a high school senior, he had participated in previous research about teacher socialization. Using Olsen's sociocultural view of teacher identity as a lens, I examined Paul's teacher identity including personal beliefs about teaching, how those interacted with professional learning and teacher education experiences, and how Paul made sense of himself as a teacher. Through data analysis I revealed three themes: Becoming Student Focused, Learning to Be Myself as a Teacher, and Taking Ownership. I recommend making preservice and cooperating music teachers more aware of teacher identity models and suggest activities to promote teacher identity development in music teacher education programs. Music teacher educators would benefit from having more teacher identity scholarship focused on music student teachers and beginning music educators.},
author = {Draves, Tami J.},
doi = {10.1177/1057083719844211},
issn = {19450079},
journal = {Journal of Music Teacher Education},
keywords = {beginning teachers,case study,identity,student teaching},
number = {1},
pages = {41--55},
publisher = {{SAGE} Publications},
title = {{Teaching Ambition Realized: Paul's Beginning Music Teacher Identity}},
volume = {29},
year = {2019}
}
@article{moore2019musical,
abstract = {This paper reports on a pilot study of the Musical Futures approach conducted in two secondary and two primary schools in Ireland. A case study approach underpinned the methodology for the study which included a survey questionnaire of students, semi-structured interviews with music teachers and principals, non-participant observation and focus groups with the students. Findings resonate with previous Musical Futures studies internationally, for example, motivation for learning, developing critical listening and ensemble skills, and enthusiasm for music as a subject. The paper will consider the implications of the study for music education policy and practice in Ireland. Insights from the study will provide key recommendations for incorporating Musical Futures in similar contexts.},
author = {Moore, Gwen},
doi = {10.1080/14613808.2019.1593954},
issn = {14699893},
journal = {Music Education Research},
keywords = {Musical futures,informal learning,non-formal teaching,primary,secondary,students,teachers},
month = {mar},
number = {3},
pages = {243--256},
publisher = {Informa {UK} Limited},
title = {{Musical futures in Ireland: findings from a pilot study in primary and secondary schools}},
volume = {21},
year = {2019}
}
@article{gabana2019a,
abstract = {Music use in golf receives minimal attention from both applied and empirical perspectives. Golfers, coaches, and sport psychology practitioners alike may benefit from understanding and utilizing music within their work. Since music use in golf has become an increasingly common practice, the purpose of the current study was to investigate current music use among golfers using a qualitative approach. Researchers aimed to identify potential psychological and physiological effects derived from music use during golf practice and pre-performance, given the limited empirical research in this area to date. Semi-structured interviews were conducted with ten amateur and semi-professional golfers (five male, five female, Mage = 22.9 years, SD = 5.04 years). Consensual qualitative research (CQR) methodology was used to analyze the interview data. Six domains emerged from the CQR analysis regarding participants' self-reported music use in golf: tempo, attention, physiological regulation, psychological regulation, effects of music on performance perceptions, and context (to use or not to use). Given the capacity of carefully selected music to elicit profound affective, neurophysiological, and behavioral responses, there is clear potential for mental performance consultants to utilize music in working with golfers in training contexts. Implications, caveats, and future research recommendations are provided.},
author = {Gabana, Nicole and Hutchinson, Jasmin and Beauchemin, James and Powless, Matthew and Cawthra, Julia and Halterman, Aaron and Steinfeldt, Jesse},
doi = {10.3390/sports7030060},
issn = {2075-4663},
journal = {Sports},
month = {mar},
number = {3},
pages = {60},
publisher = {{MDPI} {AG}},
title = {{A Qualitative Investigation of Music Use among Amateur and Semi-Professional Golfers}},
volume = {7},
year = {2019}
}
@article{kim2019music,
abstract = {Music listening is a very personal and situational behavior for modern people who always carry smartphones in everyday life. Therefore, contextual information, such as user's current activity and mood state could be used to greatly improve music recommendations. In this paper, we develop a smartphone-based mobile system that includes two core modules for recognizing human activities and then accordingly recommending music. In the proposed method, a deep residual bidirectional gated recurrent neural network is applied to obtain high activity recognition accuracy from accelerometer signals on the smartphone. In order to improve the performance of tempo-oriented music classification, an ensemble of dynamic classification using a long-term modulation spectrum and sequence classification using a short-term spectrogram is used. Music recommendation is performed using the relationship between the recognized human activities and the music files indexed by tempo-oriented music classification that reflects user preference models in order to achieve high user satisfaction. The results of comprehensive experiments on real data confirm the accuracy of the proposed activity-aware music recommendation framework.},
author = {Kim, Hyoung Gook and Kim, Gee Yeun and Kim, Jin Young},
doi = {10.1109/TCE.2019.2924177},
issn = {15584127},
journal = {IEEE Transactions on Consumer Electronics},
keywords = {Accelerometer data,deep learning,human activity recognition,music classification,music recommendation},
number = {3},
pages = {349--358},
publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
title = {{Music Recommendation System Using Human Activity Recognition from Accelerometer Data}},
volume = {65},
year = {2019}
}
@article{chen2018improving,
abstract = {In the past decades, a large number of music pieces are uploaded to the Internet every day through social networks, such as Last.fm, Spotify and YouTube, that concentrates on music and videos. We have been witnessing an ever-increasing amount of music data. At the same time, with the huge amount of online music data, users are facing an everyday struggle to obtain their interested music pieces. To solve this problem, music search and recommendation systems are helpful for users to find their favorite content from a huge repository of music. However, social influence, which contains rich information about similar interests between users and users' frequent correlation actions, has been largely ignored in previous music recommender systems. In this work, we explore the effects of social influence on developing effective music recommender systems and focus on the problem of social influence aware music recommendation, which aims at recommending a list of music tracks for a target user. To exploit social influence in social influence aware music recommendation, we first construct a heterogeneous social network, propose a novel meta path-based similarity measure called WPC, and denote the framework of similarity measure in this network. As a step further, we use the topological potential approach to mine social influence in heterogeneous networks. Finally, in order to improve music recommendation by incorporating social influence, we present a factor graphic model based on social influence. Our experimental results on one real world dataset verify that our proposed approach outperforms current state-of-the-art music recommendation methods substantially.},
author = {Chen, Jinpeng and Ying, Pinguang and Zou, Ming},
doi = {10.1007/s11042-018-5745-7},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Meta-Path,Music recommendation,Social influence,Topological potential},
month = {feb},
number = {3},
pages = {2667--2687},
publisher = {Springer Science and Business Media {LLC}},
title = {{Improving music recommendation by incorporating social influence}},
volume = {78},
year = {2019}
}
@article{vall2019order,
abstract = {The availability of increasingly larger multimedia collections has fostered extensive research in recommender systems. Instead of capturing general user preferences, the task of next-item recommendation focuses on revealing specific session preferences encoded in the most recent user interactions. This study focuses on the music domain, particularly on the task of music playlist continuation, a paradigmatic case of next-item recommendation. While the accuracy achieved in next-song recommendations is important, in this work we shift our focus toward a deeper understanding of fundamental playlist characteristics, namely the song order, the song context and the song popularity, and their relation to the recommendation of playlist continuations. We also propose an approach to assess the quality of the recommendations that mitigates known problems of off-line experiments for music recommender systems. Our results indicate that knowing a longer song context has a positive impact on next-song recommendations. We find that the long-tailed nature of the playlist datasets makes simple and highly expressive playlist models appear to perform comparably, but further analysis reveals the advantage of using highly expressive models. Finally, our experiments suggest that the song order is not crucial to accurately predict next-song recommendations.},
author = {Vall, Andreu and Quadrana, Massimo and Schedl, Markus and Widmer, Gerhard},
doi = {10.1007/s13735-019-00169-8},
issn = {2192662X},
journal = {International Journal of Multimedia Information Retrieval},
keywords = {Collaborative filtering,Music playlist continuation,Music recommender systems,Recurrent neural networks,Sequential recommendation},
number = {2},
pages = {101--113},
publisher = {Springer Science and Business Media {LLC}},
title = {{Order, context and popularity bias in next-song recommendations}},
volume = {8},
year = {2019}
}
@article{andjelkovic2019moodplay,
abstract = {A large amount of research in recommender systems focuses on algorithmic accuracy and optimization of ranking metrics. However, recent work has unveiled the importance of other aspects of the recommendation process, including explanation, transparency, control and user experience in general. Building on these aspects, this paper introduces MoodPlay, an interactive music-artists recommender system which integrates content and mood-based filtering in a novel interface. We show how MoodPlay allows the user to explore a music collection by musical mood dimensions, building upon GEMS, a music-specific model of affect, rather than the traditional Circumplex model. We describe system architecture, algorithms, interface and interactions followed by use-case and offline evaluations of the system, providing evidence of the benefits of our model based on similarities between the typical moods found in an artist's music, for contextual music recommendation. Finally, we present results of a user study (N = 279) in which four versions of the interface are evaluated with varying degrees of visualization and interaction. Results show that our proposed visualization of items and mood information improves user acceptance and understanding of both the underlying data and the recommendations. Furthermore, our analysis reveals the role of mood in music recommendation, considering both artists' mood and users' self-reported mood in the user study. Our results and discussion highlight the impact of visual and interactive features in music recommendation, as well as associated human-cognitive limitations. This research also aims to inform the design of future interactive recommendation systems.},
author = {Andjelkovic, Ivana and Parra, Denis and O'Donovan, John},
doi = {10.1016/j.ijhcs.2018.04.004},
issn = {10959300},
journal = {International Journal of Human Computer Studies},
keywords = {Affective computing,Context-aware recommendation,Mood context,Music recommendation,Recommendation interface,Recommender systems},
pages = {142--159},
publisher = {Elsevier {BV}},
title = {{Moodplay: Interactive music recommendation based on Artists' mood similarity}},
volume = {121},
year = {2019}
}
@article{wang2017learning,
abstract = {Contextual factors greatly influence users' musical preferences, so they are beneficial remarkably to music recommendation and retrieval tasks. However, it still needs to be studied how to obtain and utilize the contextual information. In this paper, we propose a context-aware music recommendation approach, which can recommend music pieces appropriate for users' contextual preferences for music. In analogy to matrix factorization methods for collaborative filtering, the proposed approach does not require music pieces to be represented by features ahead, but it can learn the representations from users' historical listening records. Specifically, the proposed approach first learns music pieces' embeddings (feature vectors in low-dimension continuous space) from music listening records and corresponding metadata. Then it infers and models users' global and contextual preferences for music from their listening records with the learned embeddings. Finally, it recommends appropriate music pieces according to the target user's preferences to satisfy her/his real-time requirements. Experimental evaluations on a real-world dataset show that the proposed approach outperforms baseline methods in terms of precision, recall, F1 score, and hitrate. Especially, our approach has better performance on sparse datasets.},
author = {Wang, Dongjing and Deng, Shuiguang and Zhang, Xin and Xu, Guandong},
doi = {10.1007/s11280-017-0521-6},
issn = {1386145X},
journal = {World Wide Web},
keywords = {Context-aware recommendation,Embedding,Music recommendation,Recommender systems},
number = {5},
pages = {1399--1423},
publisher = {Springer Science and Business Media {LLC}},
title = {{Learning to embed music and metadata for context-aware music recommendation}},
volume = {21},
year = {2018}
}
@article{wang2017sequencebased,
abstract = {Contextual factors greatly affect users' preferences for music, so they can benefit music recommendation and music retrieval. However, how to acquire and utilize the contextual information is still facing challenges. This paper proposes a novel approach for context-aware music recommendation, which infers users' preferences for music, and then recommends music pieces that fit their real-time requirements. Specifically, the proposed approach first learns the low dimensional representations of music pieces from users' music listening sequences using neural network models. Based on the learned representations, it then infers and models users' general and contextual preferences for music from users' historical listening records. Finally, music pieces in accordance with user's preferences are recommended to the target user. Extensive experiments are conducted on real world datasets to compare the proposed method with other state-of-the-art recommendation methods. The results demonstrate that the proposed method significantly outperforms those baselines, especially on sparse data.},
author = {Wang, Dongjing and Deng, Shuiguang and Xu, Guandong},
doi = {10.1007/s10791-017-9317-7},
issn = {15737659},
journal = {Information Retrieval Journal},
keywords = {Context-aware,Embedding,Neural network,Recommender systems,Sequence-based},
month = {oct},
number = {2-3},
pages = {230--252},
publisher = {Springer Science and Business Media {LLC}},
title = {{Sequence-based context-aware music recommendation}},
volume = {21},
year = {2018}
}
@article{cai2016sessionaware,
abstract = {Music recommendation is a critical technology enabling users to overcome the overload of songs in the music sites. Although existing methods of similar retrieval or sequence prediction have attained success to some extend, one important factor has not been considered in the previous work, that is, users may change their music interest in different sessions. How to define the users' current interest is still a problem. In this paper, we propose a topic-based probabilistic model for addressing this problem by developing session-aware latent topics to model the users' listening behavior. The model is designed based on the insight that users' listening behavior is subjected to not only their personal interest, but also to their special interest in the session. Specifically, when making recommendation, our model estimates the probability of the song selection based on the mixture of the two aspects with a weight-based scheme. We have conducted experiments on a real music dataset from Last.fm. The empirical results demonstrate that our model performs much better than other state-of-the-art methods.},
author = {quan Cai, Zhao and Hu, Hui},
doi = {10.1007/s00500-016-2407-4},
issn = {14337479},
journal = {Soft Computing},
keywords = {Generative model,More,Music recommendation,Recommender systems,Topic model},
month = {nov},
number = {3},
pages = {1023--1031},
publisher = {Springer Science and Business Media {LLC}},
title = {{Session-aware music recommendation via a generative model approach}},
volume = {22},
year = {2018}
}
@article{katarya2017efficient,
abstract = {Music recommender systems is an important field of research because of easy availability and use of online music. The most existing models only focus on explicit data like ratings and other user-item dimensions. A challenging problem in music recommendation is to model a variety of contextual information, such as feedback, time and location. In this article, we proposed a competent hybrid music recommender system (HMRS), which works on context and collaborative approaches. The timestamp is extracted from users listening log to construct a decision context behavior that extracted various temporal features like a week, sessions(as morning, evening or night). We used depth-first-search (DFS) algorithm which traverses the whole graph through the paths in different contexts. Bellman-Ford algorithm provides ranked list of recommended items with multi-layer context graph. We enhanced the process using particle swarm optimization (PSO) which produced highly optimized results. The dataset is used from Last.fm which contains 19,150,868 music listening logs of 992 users (till May, 4th 2009). We extract the properties of music from user's listening history and evaluate the efficient system to recommend music based on user's contextual preferences. Our system noticeably delivers the best recommendations regarding recall results when compared to existing methods.},
author = {Katarya, Rahul and Verma, Om Prakash},
doi = {10.1007/s11042-017-4447-x},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Collaborative filtering,Hybrid,Music,Particle swarm optimization,Recommender system},
month = {feb},
number = {2},
pages = {2673--2687},
publisher = {Springer Science and Business Media {LLC}},
title = {{Efficient music recommender system using context graph and particle swarm}},
volume = {77},
year = {2018}
}
@article{talbert2018an,
abstract = {The purpose of this descriptive study was to gather data to ascertain current trends in chamber music participation in older-adult ensembles. Directors (N=61) of ensembles belonging to the New Horizons International Music Association (NHIMA) served as participants in this study. Using an electronic survey instrument to collect responses, the researchers gathered information on chamber music practices within the context of the NHIMA ensemble of which the respondent was the director. Results suggest that less than half of the New Horizons ensembles currently incorporate a chamber music component into their programme. Further analysis revealed the manner in which chamber ensembles were structured, common rehearsal practices and the perceived impediments to the implementation of chamber music into a NHIMA group. The authors use these results to recommend the investigation of different chamber music models within NHIMA contexts to try and identify approaches that work, given the disparate needs of each individual NHIMA organization.},
author = {Talbert, Matthew D. and Edelman, Philip B.},
doi = {10.1386/ijcm.11.2.213_1},
issn = {17526302},
journal = {International Journal of Community Music},
keywords = {Adult amateur musicians,Chamber music,Chamber music selection,International Music Association,Lifelong learning,New Horizons,Rehearsal practice},
month = {jun},
number = {2},
pages = {213--223},
publisher = {Intellect},
title = {{An investigation into current practices and participation in new horizons chamber music}},
volume = {11},
year = {2018}
}
@article{abdul2018an,
abstract = {Recommending music based on a user's music preference is a way to improve user listening experience. Finding the correlation between the user data (e.g., location, time of the day, music listening history, emotion, etc.) and the music is a challenging task. In this paper, we propose an emotion-aware personalized music recommendation system (EPMRS) to extract the correlation between the user data and the music. To achieve this correlation, we combine the outputs of two approaches: the deep convolutional neural networks (DCNN) approach and the weighted feature extraction (WFE) approach. The DCNN approach is used to extract the latent features from music data (e.g., audio signals and corresponding metadata) for classification. In the WFE approach, we generate the implicit user rating for music to extract the correlation between the user data and the music data. In the WFE approach, we use the term-frequency and inverse document frequency (TF-IDF) approach to generate the implicit user ratings for the music. Later, the EPMRS recommends songs to the user based on calculated implicit user rating for the music. We use the million songs dataset (MSD) to train the EPMRS. For performance comparison, we take the content similarity music recommendation system (CSMRS) as well as the personalized music recommendation system based on electroencephalography feedback (PMRSE) as the baseline systems. Experimental results show that the EPMRS produces better accuracy of music recommendations than the CSMRS and the PMRSE. Moreover, we build the Android and iOS APPs to get realistic data of user experience on the EPMRS. The collected feedback from anonymous users also show that the EPMRS sufficiently reflect their preference on music.},
author = {Abdul, Ashu and Chen, Jenhui and Liao, Hua Yuan and Chang, Shun Hao},
doi = {10.3390/app8071103},
issn = {20763417},
journal = {Applied Sciences (Switzerland)},
keywords = {Convolutional neural networks,Latent features,Machine learning,Music,User preference,Weighted feature extraction},
month = {jul},
number = {7},
pages = {1103},
publisher = {{MDPI} {AG}},
title = {{An emotion-aware personalized music recommendation system using a convolutional neural networks approach}},
volume = {8},
year = {2018}
}
@article{zheng2018tagaware,
abstract = {We present a tag-aware dynamic music recommendation framework that achieves personalized and accurate music recommendations to users. The proposed framework leverages the available semantic labels (in terms of tags) of music tracks to complement a highly sparse user-item interaction matrix, which effectively addresses the data sparsity issue faced by most music recommendation systems. Music tracks are more accurately represented by aggregating the latent factors derived from both the tag space and the user interaction information. The proposed framework further employs a Gaussian state-space model to capture the evolving nature of users' preferences over time, which helps achieve time-sensitive recommendation of music. A variational approximation is developed to achieve fast inference and learning of model parameters. Experiments conducted using actual music data and comparison with state-of-the-art competitive recommendation algorithms help demonstrate the effectiveness of the proposed framework.},
author = {Zheng, Ervine and Kondo, Gustavo Yukio and Zilora, Stephen and Yu, Qi},
doi = {10.1016/j.eswa.2018.04.014},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Matrix factorization,Music recommendation,Tag aware,Temporal dynamics},
month = {sep},
pages = {244--251},
publisher = {Elsevier {BV}},
title = {{Tag-aware dynamic music recommendation}},
volume = {106},
year = {2018}
}
@article{liu2018the,
abstract = {Music listening is an inherently cultural behavior, which may be shaped by users' backgrounds and contextual characteristics. Due to geographical, socio-economic, linguistic, and cultural factors as well as friendship networks, users in different countries may have different music preferences. Investigating cultural-socio-economic factors that might be associated with between-country differences in music preferences can facilitate music information retrieval, contribute to the prediction of users' music preferences, and improve music recommendation in cross-country contexts. However, previous literature provides limited empirical evidence of the relationships between possible cross-country differences on a wide range of socio-economic aspects and those in music preferences. To bridge this research gap, and drawing on a large-scale dataset, LFM-1b, this study examines the possible relationship between cross-country differences in artist, album, and genre listening frequencies as well as the cross-country distance in geographical, socio-economic, linguistic, cultural, and friendship connections using the Quadratic Assignment Procedure. Results indicate: (1) there is no significant relationship between geographical and economic distance on album, artist, and genre preferences' distance at the country-level; (2) the cross-country distance of three cultural dimensions (masculinity, long-term orientation, and indulgence) is positively associated with both the album and artist preferences distances; (3) the between-country distance in main languages has a positive relationship with the album, artist, and genre preferences distances across countries; (4) the density of friendship connections among countries negatively correlates to the cross-country preference distances in terms of artist and genre. Findings from this study not only expand knowledge of factors related to music preferences at the country level, but also can be integrated into real-world music recommendation systems that consider country-level music preferences.},
author = {Liu, Meijun and Hu, Xiao and Schedl, Markus},
doi = {10.1371/journal.pone.0208186},
editor = {Gruebner, Oliver},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pages = {e0208186},
pmid = {30550544},
publisher = {Public Library of Science ({PLoS})},
title = {{The relation of culture, socio-economics, and friendship to music preferences: A large-scale, cross-country study}},
volume = {13},
year = {2018}
}
@article{lee2017a,
abstract = {Contextual information is helpful in building systems that can meet users' needs more efficiently and practically. Human activity provides a special kind of contextual information that can be combined with the perceived environmental data to determine appropriate service actions. In this study, we develop a smartphone-based mobile system that includes two core modules for recognizing human activities and then making music streaming recommendation accordingly. Machine learning methods with feature selection techniques are used to perform activity recognition from smartphone signals, and collaborative filtering methods are adopted for music recommendation. A series of experiments are conducted to evaluate the performance of our activity-aware framework. Moreover, we implement a mobile music streaming recommendation system on a smartphone-cloud platform to demonstrate that the proposed approach is practical and applicable to real-world applications.},
author = {Lee, Wei Po and Chen, Chun Ting and Huang, Jhih Yuan and Liang, Jhen Yi},
doi = {10.1016/j.knosys.2017.06.002},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Activity recognition,Classification,Context-awareness,Feature extraction,Mobile music recommendation,Smartphone},
month = {sep},
pages = {70--82},
publisher = {Elsevier {BV}},
title = {{A smartphone-based activity-aware system for music streaming recommendation}},
volume = {131},
year = {2017}
}
@article{aaman2016interacting,
abstract = {The rapid development in mobile computing has brought context sensing and information available for music recommendation as well. We reviewed 19 experimental contextual music systems and found that while the context factors of location, time, activity, and identity are adopted in a wide variety of ways, the systems mainly rely on common UI solutions for interacting with these factors. Specifically, context factors could be employed to offer explanations, transparency, and visualizations of music recommendations in more explorative ways, providing novel user experiences. Based on our review, we provide implications for design and research on future media discovery systems, which we believe can realize the great potential of context-aware content services.},
author = {{\AA}man, Pirkka and Liikkanen, Lassi A.},
doi = {10.1080/10447318.2016.1225881},
issn = {15327590},
journal = {International Journal of Human-Computer Interaction},
number = {3},
pages = {165--179},
publisher = {Informa {UK} Limited},
title = {{Interacting with Context Factors in Music Recommendation and Discovery}},
volume = {33},
year = {2017}
}
@article{pichl2017understanding,
abstract = {Music streaming platforms enable people to access millions of tracks using computers and mobile devices. However, users cannot browse manually millions of tracks to find music they like. Building recommender systems suggesting music fitting the current context of a user is a challenging task. A deeper understanding for the characteristics of user-curated playlists naturally contributes to more personalized recommendations. To get a deeper understanding of how users organize music nowadays, we analyze user-curated playlists from the music streaming platform Spotify. Based on the audio features of the tracks, we find an explanation of differences in the playlists using a PCA and are able to group playlists using spectral clustering. Our findings about playlist characteristics can be exploited in a SVD-based music recommender system and our proposed clustering approach for finding groups of similar playlists is easy to integrate into a recommender system using pre- or post-filtering techniques.},
author = {Pichl, Martin and Zangerle, Eva and Specht, G{\"{u}}nther},
doi = {10.4018/ijmdem.2017100103},
issn = {1947-8534},
journal = {International Journal of Multimedia Data Engineering and Management},
month = {oct},
number = {4},
pages = {44--59},
publisher = {{IGI} Global},
title = {{Understanding User-Curated Playlists on Spotify}},
volume = {8},
year = {2017}
}
@incollection{kaminskas2016emotionbased,
abstract = {Music and places can both trigger emotional responses in people. This chapter presents a technical approach that exploits the congruence of emotions raised by music and places to identify music tracks that match a place of interest (POI). Such technique can be used in location-aware music recommendation services. For instance, amobile city guide may playmusic related to the place visited by a tourist, or an in-car navigation system may adapt music to places the car is passing by. We address the problem of matching music to places by employing a controlled vocabularyof emotionlabels.Wehypothesize that thecommonalityof these emotions could provide, among other approaches, the base for establishing a degree of match between a place and a music track, i.e., finding music that “feels right” for the place. Through a series of user studies we show the correctness of our hypothesis. We compare the proposed emotion-based matching approach with a personalized approach where the music track is matched to themusic preferences of the user, and to a knowledge-based approach which matches music to places based on metadata (e.g., matching music that was composed during the same period that the place of interestwasbuilt in).We showthatwhenevaluating the goodnessoffit between places and music, personalization is not sufficient and that the users perceive the emotion- based music suggestions as better fitting the places. The results also suggest that emotion-based and knowledge-based techniques can be combined to complement each other},
author = {Kaminskas, Marius and Ricci, Francesco},
booktitle = {Human{\textendash}Computer Interaction Series},
doi = {10.1007/978-3-319-31413-6_14},
pages = {287--310},
publisher = {Springer International Publishing},
title = {{Emotion-Based Matching of Music to Places}},
year = {2016}
}
@article{lee2015userstextquotesingle,
abstract = {User studies in the music information retrieval (MIR) domain tend to be exploratory and qualitative in nature, involving a small number of users, which makes it difficult to derive broader implications for system design. In order to fill this gap, we conducted a large-scale user survey questioning various aspects of people's music information needs and behaviors. In particular, we investigated if general music users' needs and behaviors have significantly changed over time by comparing our current survey results with a similar survey conducted in 2004. In this paper, we present the key findings from the survey data and discuss 4 emergent themes - (a) the shift in access and use of personal music collections; (b) the growing need for tools to support collaborative music seeking, listening, and sharing; (c) the importance of "visual" music experiences; and (d) the need for ontologies for providing rich contextual information. We conclude by making specific recommendations for improving the design of MIR systems and services.},
author = {Lee, Jin Ha and Cho, Hyerim and Kim, Yea Seul},
doi = {10.1002/asi.23471},
issn = {23301643},
journal = {Journal of the Association for Information Science and Technology},
keywords = {information needs,information seeking,music,personal information management,user behavior},
number = {6},
pages = {1301--1330},
publisher = {Wiley},
title = {{Users' music information needs and behaviors: Design implications for music information retrieval systems}},
volume = {67},
year = {2016}
}
@article{keith2016studyabroad,
abstract = {Music therapists are expected to attain and maintain a broad range of multicultural competencies. In order to do so, a group of students participated in a study-abroad program in music therapy, involving classroom learning, community building, a clinical placement, and attendance at an international conference. A sample of these students participated in a qualitative interview study to explore what they learned. Results suggest that the program led to changes in students' views of music therapy practice, the music therapy profession, and their definition of music therapy. The profession of music therapy is thus viewed as culturally situated, underscoring the importance of cultural self-awareness. The discussion contextualizes the results of these learning experiences using a Piagetian framework. Recommendations for music therapy faculty and organizations are drawn from the study findings. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
author = {Keith, Douglas R.},
doi = {10.1093/mtp/miw014},
issn = {0734-6875},
journal = {Music Therapy Perspectives},
month = {jun},
pages = {miw014},
publisher = {Oxford University Press ({OUP})},
title = {{Study-Abroad in Music Therapy: Cultural Immersion as a Form of Self-Experience}},
year = {2016}
}
@incollection{lugovic2016overview,
author = {Lugovic, Sergej},
booktitle = {Advances in Multimedia and Interactive Technologies},
doi = {10.4018/978-1-5225-0270-8.ch007},
pages = {121--145},
publisher = {{IGI} Global},
title = {{Overview of Approaches and Future Challenges for Development of Music Recommendation Socio-Technical Systems}},
year = {2016}
}
@article{cheng2016on,
abstract = {Rapid advances in mobile devices and cloud-based music service now allow consumers to enjoy music anytime and anywhere. Consequently, there has been an increasing demand in studying intelligent techniques to facilitate context-aware music recommendation. However, one important context that is generally overlooked is user's venue, which often includes surrounding atmosphere, correlates with activities, and greatly influences the user's music preferences. In this article, we present a novel venue-aware music recommender system called VenueMusic to effectively identify suitable songs for various types of popular venues in our daily lives. Toward this goal, a Location-aware Topic Model (LTM) is proposed to (i) mine the common features of songs that are suitable for a venue type in a latent semantic space and (ii) represent songs and venue types in the shared latent space, in which songs and venue types can be directly matched. It is worth mentioning that to discover meaningful latent topics with the LTM, a Music Concept Sequence Generation (MCSG) scheme is designed to extract effective semantic representations for songs. An extensive experimental study based on two large music test collections demonstrates the effectiveness of the proposed topic model and MCSG scheme. The comparisons with state-of-the-art music recommender systems demonstrate the superior performance of VenueMusic system on recommendation accuracy by associating venue and music contents using a latent semantic space. This work is a pioneering study on the development of a venue-aware music recommender system. The results show the importance of considering the influence of venue types in the development of context-aware music recommender systems.},
author = {Cheng, Zhiyong and Shen, Jialie},
doi = {10.1145/2846092},
issn = {15582868},
journal = {ACM Transactions on Information Systems},
keywords = {Algorithms,Design,Experimentation,Human factors},
number = {2},
pages = {1--32},
publisher = {Association for Computing Machinery ({ACM})},
title = {{On effective location-aware music recommendation}},
volume = {34},
year = {2016}
}
@article{yang2015quantitative,
abstract = {Context-based services have attracted increasing attention because of the prevalence of sensor-rich mobile devices such as smartphones. The idea is to recommend information that a user would be interested in according to the user's surrounding context. Although remarkable progress has been made to contextualize music playback, relatively little research has been made using a large collection of real-life listening records collected in situ. In light of this fact, we present in this article a quantitative study of the personal, situational, and musical factors of musical preference in a smartphone context, using a new dataset comprising the listening records and self-report context annotation of 48 participants collected over 3wk via an Android app. Although the number of participants is limited and the population is biased towards students, the dataset is unique in that it is collected in a daily context, with sensor data and music listening profiles recorded at the same time. We investigate 3 core research questions evaluating the strength of a rich set of low-level and high-level audio features for music usage auto-tagging (i.e., music preference in different user activities), the strength of time-domain and frequency-domain sensor features for user activity classification, and how user factors such as personality traits are correlated with the predictability of music usage and user activity, using a closed set of 8 activity classes. We provide an in-depth discussion of the main findings of this study and their implications for the development of context-based music services for smartphones.},
author = {Yang, Yi Hsuan and Teng, Yuan Ching},
doi = {10.1145/2738220},
issn = {21606463},
journal = {ACM Transactions on Interactive Intelligent Systems},
keywords = {Context-aware music recommendation,Mobile application,Music emotion recognition,Music information retrieval,Smartphone},
month = {oct},
number = {3},
pages = {1--30},
publisher = {Association for Computing Machinery ({ACM})},
title = {{Quantitative study of music listening behavior in a smartphone context}},
volume = {5},
year = {2015}
}
@article{hu2015safedj,
abstract = {Driving is an integral part of our everyday lives, but it is also a time when people are uniquely vulnerable. Previous research has demonstrated that not only does listening to suitable music while driving not impair driving performance, but it could lead to an improved mood and a more relaxed body state, which could improve driving performance and promote safe driving significantly. In this article, we propose SAfeDJ, a smartphone-based situation-aware music recommendation system, which is designed to turn driving into a safe and enjoyable experience. SAfeDJ aims at helping drivers to diminish fatigue and negative emotion. Its design is based on novel interactive methods, which enable in-car smartphones to orchestrate multiple sources of sensing data and the drivers' social context, in collaboration with cloud computing to form a seamless crowdsensing solution. This solution enables different smartphones to collaboratively recommend preferable music to drivers according to each driver's specific situations in an automated and intelligent manner. Practical experiments of SAfeDJ have proved its effectiveness in music-mood analysis, and moodfatigue detections of drivers with reasonable computation and communication overheads on smartphones. Also, our user studies have demonstrated that SAfeDJ helps to decrease fatigue degree and negative mood degree of drivers by 49.09% and 36.35%, respectively, compared to traditional smartphone-based music player under similar driving situations.},
author = {Hu, Xiping and Deng, Junqi and Zhao, Jidi and Hu, Wenyan and Ngai, Edith C.H. and Wang, Renfei and Shen, Johnny and Liang, Min and Li, Xitong and Leung, Victor C.M. and Kwok, Yu Kwong},
doi = {10.1145/2808201},
issn = {15516865},
journal = {ACM Transactions on Multimedia Computing, Communications and Applications},
keywords = {Cloud,Context,Crowdsensing,Driving,Music mood,Smartphones},
month = {oct},
number = {1s},
pages = {1--24},
publisher = {Association for Computing Machinery ({ACM})},
title = {{SAfeDJ: A crowd-cloud codesign approach to situation-aware music delivery for drivers}},
volume = {12},
year = {2015}
}
@article{tomavsev2014image,
abstract = {We present a novel tool for image data visualization and analysis, Image Hub Explorer. It is aimed at developers and researchers alike and it allows the users to examine various aspects of content-based image retrieval and object recognition under different built-in metrics and models. Image Hub Explorer provides the tools for understanding the distribution of influence in the data, primarily by examining the emerging hub images. Hubness is an aspect of the well-known curse of dimensionality that hampers the effectiveness of many information systems. Its consequences were thoroughly examined in the context of music/audio search and recommendation, but not in case of image retrieval and object recognition. Image Hub Explorer was made with the goal of raising awareness of the hubness phenomenon and offering potential solutions by implementing state-of-the-art hubness-aware metric learning, ranking and classification methods. Various visualization components allow for a quick identification of critical issues and we hope that they will prove helpful in working with large image datasets. We demonstrate the effectiveness of the implemented methods in various object recognition tasks.},
author = {Toma{\v{s}}ev, Nenad and Mladeni{\'{c}}, Dunja},
doi = {10.1007/s11042-014-2254-1},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Hubness,Image retrieval,Machine learning,Object recognition,Visualization,k-nearest neighbors},
month = {sep},
number = {24},
pages = {11653--11682},
publisher = {Springer Science and Business Media {LLC}},
title = {{Image hub explorer: evaluating representations and metrics for content-based image retrieval and object recognition}},
volume = {74},
year = {2015}
}
@article{deng2015exploring,
abstract = {Context-aware recommendation has become increasingly important and popular in recent years when users are immersed in enormous music contents and have difficulty to make their choices. User emotion, as one of the most important contexts, has the potential to improve music recommendation, but has not yet been fully explored due to the great difficulty of emotion acquisition. This article utilizes users' microblogs to extract their emotions at different granularity levels and during different time windows. The approach then correlates three elements: user, music and the user's emotion when he/she is listening to the music piece. Based on the associations extracted from a data set crawled from a Chinese Twitter service, we develop several emotion-aware methods to perform music recommendation. We conduct a series of experiments and show that the proposed solution proves that considering user emotional context can indeed improve recommendation performance in terms of hit rate, precision, recall, and F1 score.},
author = {Deng, Shuiguang and Wang, Dongjing and Li, Xitong and Xu, Guandong},
doi = {10.1016/j.eswa.2015.08.029},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Emotion analysis,Emotion-aware,Music recommendation,Song-document association},
number = {23},
pages = {9284--9293},
publisher = {Elsevier {BV}},
title = {{Exploring user emotion in microblogs for music recommendation}},
volume = {42},
year = {2015}
}
@article{kirkwood2014the,
abstract = {Practitioners are increasingly utilising Information communication technologies (ICT) with very young children in early childhood settings. A debate is raging in the media as to the pros and cons of 'virtual-electronic' versus 'material world' active learning opportunities. However, when this scenario is played out with Aboriginal and Torres Strait Islander Australian children, it is even more contentious because the technological changes have resulted in shifting responsibility for teaching and learning of Aboriginal and Torres Strait Islander songs, dances and cultural heritage to a new physical and social environment which may distance musical development from community life. The rate of social change has been enormous, so in many cases there has not been adequate consultation and negotiation as to how early childhood professionals are to effectively implement the national Early Years Learning Framework (EYLF) (DEEWR, 2009) with respect for Aboriginal and Torres Strait Islander music culture. The purpose of this paper is to problematise the increasing distance of musical development away from Aboriginal and Torres Strait Islander communities, and to propose new methods for exploring how digital technologies may be utilised for promoting children's musical development in various contexts. The findings are applied to early childhood practitioner recommendations for future community-led music research.},
author = {Kirkwood, Sandra and Miller, Adrian},
doi = {10.1177/183693911403900113},
issn = {18369391},
journal = {Australasian Journal of Early Childhood},
month = {mar},
number = {1},
pages = {94--101},
publisher = {{SAGE} Publications},
title = {{The impact of new technologies on musical learning of indigenous Australian children}},
volume = {39},
year = {2014}
}
@article{schedl2014music,
abstract = {We provide a survey of the field of Music Information Retrieval (MIR), in particular paying attention to latest developments, such as semantic auto-tagging and user-centric retrieval and recommendation approaches. We first elaborate on well-established and proven methods for feature extraction and music indexing, from both the audio signal and contextual data sources about music items, such as web pages or collaborative tags. These in turn enable a wide variety of music retrieval tasks, such as semantic music search or music identification ("query by example"). Subsequently, we review current work on user analysis and modeling in the context of music recommendation and retrieval, addressing the recent trend towards user-centric and adaptive approaches and systems. A discussion follows about the important aspect of how various MIR approaches to different problems are evaluated and compared. Eventually, a discussion about the major open challenges concludes the survey.},
author = {Schedl, Markus and G{\'{o}}mez, Emilia and Urbano, Juli{\'{a}}n},
doi = {10.1561/1500000042},
issn = {15540677},
journal = {Foundations and Trends in Information Retrieval},
number = {2-3},
pages = {127--261},
publisher = {Now Publishers},
title = {{Music information retrieval: Recent developments and applications}},
volume = {8},
year = {2014}
}
@article{braunhofer2013locationaware,
abstract = {The increasing amount of online music content has opened opportunities for implementing new effective information access services—commonly known as music recommender systems—that support music navigation, discovery, sharing, and formation of user communities. In recent years, a new research area of contextual music recommendation and retrieval has emerged. Context-aware music recommender systems are capable of suggesting music items taking into consideration contextual conditions, such as the user's mood or location, that may influence the user's preferences at a particular moment. In this work, we consider a particular kind of context-aware recommendation task—selecting music content that fits a place of interest (POI). To address this problem we have used emotional tags assigned to both music tracks and POIs, and we have considered a set of similarity metrics for tagged resources to establish a match between music tracks and POIs. Following an initial web-based evaluation of the core matching technique, we have developed a mobile application that suggests an itinerary and plays recommended music for each visited POI, and evaluated it in a live user study. The results of the study show that users judge the recommended music as suited for the POIs, and that the music is rated higher when it is played in this usage scenario.},
author = {Braunhofer, Matthias and Kaminskas, Marius and Ricci, Francesco},
doi = {10.1007/s13735-012-0032-2},
issn = {2192662X},
journal = {International Journal of Multimedia Information Retrieval},
keywords = {Affective computing,Location-aware services,Mobile services,Music recommender systems,Social tagging},
number = {1},
pages = {31--44},
publisher = {Springer Science and Business Media {LLC}},
title = {{Location-aware music recommendation}},
volume = {2},
year = {2013}
}
@article{rho2011implementing,
abstract = {With the advent of the ubiquitous era, many studies have been devoted to various situation-aware services in the semantic web environment. One of the most challenging studies involves implementing a situation-aware personalized music recommendation service which considers the user's situation and preferences. Situation-aware music recommendation requires multidisciplinary efforts including low-level feature extraction and analysis, music mood classification and human emotion prediction. In this paper, we propose a new scheme for a situation-aware/user-adaptive music recommendation service in the semantic web environment. To do this, we first discuss utilizing knowledge for analyzing and retrieving music contents semantically, and a user adaptive music recommendation scheme based on semantic web technologies that facilitates the development of domain knowledge and a rule set. Based on this discussion, we describe our Context-based Music Recommendation (COMUS) ontology for modeling the user's musical preferences and contexts, and supporting reasoning about the user's desired emotions and preferences. Basically, COMUS defines an upper music ontology that captures concepts on the general properties of music such as titles, artists and genres. In addition, it provides functionality for adding domain-specific ontologies, such as music features, moods and situations, in a hierarchical manner, for extensibility. Using this context ontology, we believe that logical reasoning rules can be inferred based on high-level (implicit) knowledge such as situations from low-level (explicit) knowledge. As an innovation, our ontology can express detailed and complicated relations among music clips, moods and situations, which enables users to find appropriate music. We present some of the experiments we performed as a casestudy for music recommendation. {\textcopyright} Springer Science+Business Media, LLC 2011.},
author = {Rho, Seungmin and Song, Seheon and Nam, Yunyoung and Hwang, Eenjun and Kim, Minkoo},
doi = {10.1007/s11042-011-0803-4},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Customization,Ontology,Reasoning,Semantic web,User profiles},
month = {may},
number = {2},
pages = {259--282},
publisher = {Springer Science and Business Media {LLC}},
title = {{Implementing situation-aware and user-adaptive music recommendation service in semantic web and real-time multimedia computing environment}},
volume = {65},
year = {2013}
}
@article{solli2013toward,
abstract = {Background: The perspective of mental health recovery is increasingly shaping mental health care policies. Current texts in music therapy identify the importance of this critical and user-oriented perspective, but the relevance and implications for music therapy need to be outlined. Objective: This study explores service users' experiences of music therapy in mental health care, and the potential role of music therapy in the development of recovery-oriented service provision. Methods: We conducted a qualitative meta-synthesis of studies examining service users' experiences in music therapy; included were 14 studies with a total of 113 participants. Both first-hand account of participants and the researchers' representations of such statements were taken into account in the analysis. Findings: A taxonomy of four areas of users' experiences was identified: "having a good time;" "being together;" "feeling;"and "being someone."These core categories point towards music therapy as an arena that can be used by persons with mental health problems in their personal and social recovery process. Music therapy can contribute to the quality of mental health care by providing an arena for stimulation and development of strengths and resources that may contribute to growth of positive identity and hope for people with mental illness. Conclusions: The findings from this meta-synthesis indicate that the provision of music therapy closely resembles recognized benefits of a recovery-oriented practice. Awareness of users' self-determination and the development of a strength-based and contextual approach to music therapy that fosters mutual empowering relationships are recommended {\textcopyright} 2013 by the American Music Therapy Association.},
author = {Solli, Hans Petter and Rolvsjord, Randi and Borg, Marit},
doi = {10.1093/jmt/50.4.244},
issn = {00222917},
journal = {Journal of Music Therapy},
number = {4},
pages = {244--273},
pmid = {25014667},
publisher = {Oxford University Press ({OUP})},
title = {{Toward understanding music therapy as a recovery-oriented practice within mental health care: A meta-synthesis of service users' experiences}},
volume = {50},
year = {2013}
}
@article{clark2013the,
abstract = {Abstract Interest in musicians' health and well-being is growing, reflected by increasing numbers of investigations into the physicality and psychology of musical performance. Within sport and dance, screening and profiling programmes, especially of the musculoskeletal system, have furthered understanding on not only physical and psychological capabilities and demands but also musculoskeletal injury mechanisms and susceptibility. This article engages with questions relating to the development and delivery of musician-specific health screening programmes. Effective screening can offer a variety of benefits for musicians, providing informed recommendations for sustaining performance-related fitness across educational and professional contexts. Employing an interdisciplinary approach when developing screening programmes is essential, as is the ecological appropriateness of the measures used. The implications inherent in delivering and sustaining successful screening programmes in schools and conservatoires are discussed. {\textcopyright} Clinical Rheumatology 2013.},
author = {Clark, Terry and Williamon, Aaron and Redding, Emma},
doi = {10.1007/s10067-013-2203-9},
issn = {14349949},
journal = {Clinical Rheumatology},
keywords = {Conservatoires,Injury prevention,Musicians' health,Performance science,Screening},
month = {feb},
number = {4},
pages = {497--500},
pmid = {23417346},
publisher = {Springer Science and Business Media {LLC}},
title = {{The value of health screening in music schools and conservatoires}},
volume = {32},
year = {2013}
}
@article{knees2013a,
abstract = {In this survey article, we give an overview of methods for music similarity estimation and music recommendation based on music context data. Unlike approaches that rely on music content and have been researched for almost two decades, music-contextbased (or contextual) approaches to music retrieval are a quite recent field of research within music information retrieval (MIR). Contextual data refers to all music-relevant information that is not included in the audio signal itself. In this article, we focus on contextual aspects of music primarily accessible through web technology. We discuss different sources of context-based data for individual music pieces and for music artists. We summarize various approaches for constructing similarity measures based on the collaborative or cultural knowledge incorporated into these data sources. In particular, we identify and review three main types of context-based similarity approaches: text-retrieval-based approaches (relying on web-texts, tags, or lyrics), cooccurrence-based approaches (relying on playlists, page counts, microblogs, or peer-to-peer-networks), and approaches based on user ratings or listening habits. This article elaborates the characteristics of the presented context-based measures and discusses their strengths as well as their weaknesses. {\textcopyright} 2013 ACM.},
author = {Knees, Peter and Schedl, Markus},
doi = {10.1145/2542205.2542206},
issn = {15516857},
journal = {ACM Transactions on Multimedia Computing, Communications and Applications},
keywords = {Music context,Music information retrieval,Music recommendation,Music similarity,Survey},
number = {1},
pages = {1--21},
publisher = {Association for Computing Machinery ({ACM})},
title = {{A survey of music similarity and recommendation from music context data}},
volume = {10},
year = {2013}
}
@article{yoon2012music,
abstract = {Recently, many researches of modeling or measuring human feeling have been conducted to understand human emotions. However, researches on music-related human emotions have much difficulty due to the subjective perception of emotions. We selected low-level musical features which may trigger human emotions, based on TV music program's audience rating information and the corresponding music. In this program, audience was requested to rate music of the contestants and to select their preferred music based on their emotional feelings. In addition, we implemented personalized music recommendation system using selected features, context information and listening history. In the experimental results, we confirmed that selected features can be reliable features when these features are used in music recommendation systems. {\textcopyright} 1975-2011 IEEE.},
author = {Yoon, Kyoungro and Lee, Jonghyung and Kim, Min Uk},
doi = {10.1109/TCE.2012.6227467},
issn = {00983063},
journal = {IEEE Transactions on Consumer Electronics},
keywords = {Emotion triggering low-level feature,Low-level feature selection,Musical emotion,Personalized music recommendation system},
month = {may},
number = {2},
pages = {612--618},
publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
title = {{Music recommendation system using emotion triggering low-level features}},
volume = {58},
year = {2012}
}
@article{kaminskas2012contextual,
abstract = {Increasing amount of online music content has opened new opportunities for implementing new effective information access services-commonly known as music recommender systems-that support music navigation, discovery, sharing, and formation of user communities. In the recent years a new research area of contextual (or situational) music recommendation and retrieval has emerged. The basic idea is to retrieve and suggest music depending on the user's actual situation, for instance emotional state, or any other contextual conditions that might influence the user's perception of music. Despite the high potential of such idea, the development of real-world applications that retrieve or recommend music depending on the user's context is still in its early stages. This survey illustrates various tools and techniques that can be used for addressing the research challenges posed by context-aware music retrieval and recommendation. This survey covers a broad range of topics, starting from classical music information retrieval (MIR) and recommender system (RS) techniques, and then focusing on context-aware music applications as well as the newer trends of affective and social computing applied to the music domain. {\textcopyright} 2012 Elsevier Inc.},
author = {Kaminskas, Marius and Ricci, Francesco},
doi = {10.1016/j.cosrev.2012.04.002},
issn = {15740137},
journal = {Computer Science Review},
keywords = {Affective computing,Context-aware services,Music information retrieval,Music recommender systems,Social computing},
month = {may},
number = {2-3},
pages = {89--119},
publisher = {Elsevier {BV}},
title = {{Contextual music information retrieval and recommendation: State of the art and challenges}},
volume = {6},
year = {2012}
}
@article{hsiao2011from,
abstract = {This phenomenological study examines the thematic structure of reentry transition for international music therapy graduates who have returned home after studying in the United States. Emphasis is placed upon career development. Standardized open-ended interviews were used to obtain rich and in-depth descriptions of the participants' experiences. Ten music therapists from six countries participated in the study. The themes that emerged from the data include moving from the ideal to the real world, shifting from the role of student to professional, confronting reality and working through challenges, and achieving personal growth and self-transformation. The dynamics of cross-cultural comparison, confronting the home culture, and redefining music therapy and professional identities within the local cultural context are illustrated via quotations from the participants. Implications and recommendations for music therapy education and career preparation for international graduates are discussed. {\textcopyright} 2011 by the American Music Therapy Association.},
author = {Hsiao, Feilin},
doi = {10.1093/jmt/48.4.420},
issn = {00222917},
journal = {Journal of Music Therapy},
number = {4},
pages = {420--439},
publisher = {Oxford University Press ({OUP})},
title = {{From the ideal to the real world: A phenomenological inquiry into student sojourners' reentry adaptation}},
volume = {48},
year = {2011}
}
@article{han2009music,
abstract = {Context-based music recommendation is one of rapidly emerging applications in the advent of ubiquitous era and requires multidisciplinary efforts including low level feature extraction and music classification, human emotion description and prediction, ontology-based representation and recommendation, and the establishment of connections among them. In this paper, we contributed in three distinctive ways to take into account the idea of context awareness in the music recommendation field. Firstly, we propose a novel emotion state transition model (ESTM) to model human emotional states and their transitions by music. ESTM acts like a bridge between user situation information along with his/her emotion and low-level music features. With ESTM, we can recommend the most appropriate music to the user for transiting to the desired emotional state. Secondly, we present context-based music recommendation (COMUS) ontology for modeling user's musical preferences and context, and for supporting reasoning about the user's desired emotion and preferences. The COMUS is music-dedicated ontology in OWL constructed by incorporating domain-specific classes for music recommendation into the Music Ontology, which includes situation, mood, and musical features. Thirdly, for mapping low-level features to ESTM, we collected various high-dimensional music feature data and applied nonnegative matrix factorization (NMF) for their dimension reduction. We also used support vector machine (SVM) as emotional state transition classifier. We constructed a prototype music recommendation system based on these features and carried out various experiments to measure its performance. We report some of the experimental results. {\textcopyright} 2009 Springer Science+Business Media, LLC.},
author = {Han, Byeong Jun and Rho, Seungmin and Jun, Sanghoon and Hwang, Eenjun},
doi = {10.1007/s11042-009-0332-6},
issn = {13807501},
journal = {Multimedia Tools and Applications},
keywords = {Classification,Emotion,Emotion state transition model,Mood,Music information retrieval,Recommendation},
number = {3},
pages = {433--460},
publisher = {Springer Science and Business Media {LLC}},
title = {{Music emotion classification and context-based music recommendation}},
volume = {47},
year = {2010}
}
@article{otextquotesinglecallaghan2010oncology,
abstract = {Objective: Peter MacCallum Cancer Centre has one of the world's most enduring staff Christmas choirs. Commencing in 1956, the choir performs in a cafeteria, patient wards, and outpatient waiting areas before each Christmas. With recent emphasis on oncology staff support needs the choir's relevance warranted investigation. This constructivist research examined what effect the staff Christmas choir had on the choir members and staff bystanders in 2008. Methods: Sampling was convenience and purposive. Staff choir members were invited to participate during rehearsals, and staff bystanders were invited at seven choir performances in the hospital. Respondents completed anonymous and semistructured questionnaires and the conductor (of 29 years) was interviewed. The inductive, comparative, and cyclic data analyses were informed by grounded theory and qualitative interrater reliability was performed. Results: Questionnaires from 64 staff were returned. The choir elicited positive emotions, memories, Christmas spirit, hospital community and/or work-life effects for many staff, in a cancer context described as sometimes "overwhelming" and "stressful." Choir members' reactions included stress relief, friendship and feeling rewarded. Bystanders' reactions included feeling uplifted, inspired and moved. Suggestions for future performances were offered, including musical acknowledgement of other religious festivals. Two respondents were concerned about intrusive effects on patients and work practices. Discussion: A staff Christmas choir supported most choir member and staff bystander respondents in an oncology hospital and is recommended in comparable contexts. Further investigation is warranted to extend understanding about Christmas music's effects in palliative care settings. {\textcopyright} 2010 Mary Ann Liebert, Inc.},
author = {O'Callaghan, Clare C. and Hornby, Colin J. and Pearson, Elizabeth J.M. and Ball, David L.},
doi = {10.1089/jpm.2010.0355},
issn = {10966218},
journal = {Journal of Palliative Medicine},
number = {12},
pages = {1421--1425},
pmid = {21117947},
publisher = {Mary Ann Liebert Inc},
title = {{Oncology staff reflections about a 52-year-old staff Christmas choir: Constructivist research}},
volume = {13},
year = {2010}
}
@article{su2010music,
abstract = {Mobile devices such as smart phones are becoming popular, and realtime access to multimedia data in different environments is getting easier. With properly equipped communication services, users can easily obtain the widely distributed videos, music, and documents they want. Because of its usability and capacity requirements, music is more popular than other types of multimedia data. Documents and videos are difficult to view on mobile phones' small screens, and videos' large data size results in high overhead for retrieval. But advanced compression techniques for music reduce the required storage space significantly and make the circulation of music data easier. This means that users can capture their favorite music directly from the Web without going to music stores. Accordingly, helping users find music they like in a large archive has become an attractive but challenging issue over the past few years. {\textcopyright} 2010 IEEE.},
author = {Su, Ja Hwung and Yeh, Hsin Ho and Yu, Philip S. and Tseng, Vincent S.},
doi = {10.1109/MIS.2010.23},
issn = {15411672},
journal = {IEEE Intelligent Systems},
number = {1},
pages = {16--26},
publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
title = {{Music recommendation using content and context information mining}},
volume = {25},
year = {2010}
}
